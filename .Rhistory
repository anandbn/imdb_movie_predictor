str(myT2)
myT3 <- subset(myT2,
user_name1=as.integer(trainSmall$user_name),
cvtd_timestamp1=as.integer(trainSmall$cvtd_timestamp),
new_window1=ifelse(trainSmall$new_window=="yes",1,0),
classe1=as.integer(trainSmall$classe)
)
corr <- cor(subset(myT3,select=-c(user_name,cvtd_timestamp,new_window,classe)),method="pearson")
corrIdx <- findCorrelation(corr,cutoff = 0.8)
names(trainSmall2)[corrIdx] # these are the columns which are 80% correlated
corrIdx <- findCorrelation(corr,cutoff = 0.8)
names(myT3)[corrIdx] # these are the columns which are 80% correlated
cor(myT3)
sapply(myT3,class)
myT3$user_name <- as.integer(myT3$user_name)
myT3$new_window <- ifelse(myT3$new_window=="yes",1,0)
sapply(myT3,class)
cor(myT3)
trLoc <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
tstLoc <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trLoc,destfile = "training.csv",method="curl")
download.file(tstLoc,destfile = "testing.csv",method="curl")
training <- read.csv("training.csv",na.strings = c("NA","#DIV/0!",""))
testing <- read.csv("testing.csv",na.strings = c("NA","#DIV/0!",""))
naCols
str(training)
naCols <- sapply(seq_len(ncol(training)), function(x) if(sum(is.na(training[,x]))>0.5*nrow(training)) {return(TRUE)} else {return(FALSE)})
dim(training)
trainSmall <- training[,!naCols]
dim(trainSmall)
naRows <- sapply(seq_len(nrow(trainSmall)), function(x) if(sum(is.na(trainSmall[1,]))>0) {return(TRUE)} else {return(FALSE)})
trainSmall1 <- trainSmall[!naRows,]
dim(traingSmall1)
dim(trainSmall1)
trainSmall <- trainSmall[!naRows,]
str(trainSmall)
trainSmall2 <- subset(trainSmall,
user_name1=as.integer(trainSmall$user_name),
cvtd_timestamp1=as.integer(trainSmall$cvtd_timestamp),
new_window1=ifelse(trainSmall$new_window=="yes",1,0),
classe1=as.integer(trainSmall$classe)
)
str(trainSmall2)
corr <- cor(subset(trainSmall2,select=-c(user_name,cvtd_timestamp,new_window,classe)),method="pearson")
corrIdx <- findCorrelation(corr,cutoff = 0.8)
corrIdx <- findCorrelation(corr,cutoff = 0.8)
library(caretEnsemble)
installed.packages("caretEnsemble")
?findCorrelation
library(caret)
corrIdx <- findCorrelation(corr,cutoff = 0.8)
names(trainSmall2)[corrIdx]
modFit <- train(classe~.,method="rpart",data=trainSmall)
testSmall <- myTesting[,!naCols]
inTrain <- createDataPartition(trainSmall$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
modFit <- train(classe~.,method="rpart",data=myTraining)
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]
nzv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv$nzv==FALSE]
dim(myTraining);dim(myTesting)
cols <- cbind(names(myTraining),names(myTesting))
cols
myTraining <- myTraining[c(-1)]
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
trainingV3 <- trainingV3[ , -j]
}
}
}
}
# Set back to the original variable name
myTraining <- trainingV3
rm(trainingV3)
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58])  # remove the classe column
myTesting <- myTesting[clean1]         # allow only variables in myTesting that are also in myTraining
testing <- testing[clean2]             # allow only variables in testing that are also in myTraining
dim(myTesting)
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
# To get the same class between testing and myTraining
testing <- rbind(myTraining[2, -58] , testing)
testing <- testing[-1,]
set.seed(12345)
modFit <- train(classe~.,method="rpart",data=myTraining)
pred <- predict(modFit,newdata = myTesting)
confusionMatrix(pred,myTesting$classe)
?train
names(getModelInfo())
grep("^r",names(getModelInfo()))
names(getModelInfo()[grep("^r",names(getModelInfo()))]
names(getModelInfo())[grep("^r",names(getModelInfo()))]
modFit <- train(classe~.,method="rf",data=myTraining)
trLoc = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
tstLoc = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trLoc,destfile = "training.csv")
download.file(tstLoc,destfile = "testing.csv")
training <- read.csv("training.csv",na.strings = c("NA","#DIV/0!",""))
testing <- read.csv("testing.csv",na.string=c("NA","#DIV/0!",""))
str(training)
nzv <- nearZeroVar(training, saveMetrics= TRUE)
library(care)
library(caret)
nzv <- nearZeroVar(training, saveMetrics= TRUE)
training <- training[,nzv$nzv==FALSE]
dim(training)
naCols <- sapply(seq_len(ncol(training)), function(x) if(sum(is.na(training[,x]))>0.5*nrow(training)) {return(TRUE)} else {return(FALSE)})
trainSmall <- training[,!naCols]
dim(trainSmall)
str(trainSmall)
training$X <- NULL
training$user_name <- as.integer(training$user_name)
str(trainSmall)
levels(trainSmall$user_name)
as.numeric(levels(trainSmall$user_name))
as.numeric(levels(trainSmall$user_name))[trainSmall$user_name]
trainSmall$user_name <- as.numeric(as.character(trainSmall$user_name))
sum(is.na(trainSmall$user_name))
trainSmall <- training[,!naCols]
dim(training)
naCols <- sapply(seq_len(ncol(training)), function(x) if(sum(is.na(training[,x]))>0.5*nrow(training)) {return(TRUE)} else {return(FALSE)})
trainSmall <- training[,!naCols]
sum(is.na(trainSmall$user_name))
trainSmall[1,]$user_name
trainSmall[c(1:5),]$user_name
head(trainSmall)
head(trainSmall[,c(1:10)])
table(trainSmall$user_name)
trLoc = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
tstLoc = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trLoc,destfile = "training.csv")
download.file(tstLoc,destfile = "testing.csv")
training <- read.csv("training.csv",na.strings = c("NA","#DIV/0!",""))
testing <- read.csv("testing.csv",na.string=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
library(caret)
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]
nzv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv$nzv==FALSE]
myTraining <- myTraining[c(-1)]
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
trainingV3 <- trainingV3[ , -j]
}
}
}
}
# Set back to the original variable name
myTraining <- trainingV3
rm(trainingV3)
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58])  # remove the classe column
myTesting <- myTesting[clean1]         # allow only variables in myTesting that are also in myTraining
testing <- testing[clean2]             # allow only variables in testing that are also in myTraining
dim(myTesting)
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
# To get the same class between testing and myTraining
testing <- rbind(myTraining[2, -58] , testing)
testing <- testing[-1,]
set.seed(12345)
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
library(rpart)
set.seed(12345)
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
cmtree <- confusionMatrix(predictionsA1, myTesting$classe)
cmtree
set.seed(12345)
modFitB1 <- randomForest(classe ~ ., data=myTraining)
predictionB1 <- predict(modFitB1, myTesting, type = "class")
library(randomForest)
set.seed(12345)
modFitB1 <- randomForest(classe ~ ., data=myTraining)
predictionB1 <- predict(modFitB1, myTesting, type = "class")
predictionB1 <- predict(modFitB1, myTesting, type = "class")
cmrf <- confusionMatrix(predictionB1, myTesting$classe)
cmrf
trLoc = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
tstLoc = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trLoc,destfile = "training.csv")
download.file(tstLoc,destfile = "testing.csv")
training <- read.csv("training.csv",na.strings = c("NA","#DIV/0!",""))
testing <- read.csv("testing.csv",na.string=c("NA","#DIV/0!",""))
library(caret)
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]
nzv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv$nzv==FALSE]
training_3 <- myTraining
names(myTraining[1]
)
names(myTraining)[1]
myFun < function(i,j){grep(names(myTraining[i]), names(training_3)[j]}
myFun < function(i,j){grep(names(myTraining[i]), names(training_3)[j])}
myFun <- function(i,j){grep(names(myTraining[i]), names(training_3)[j])}
myFun(1,1)
myFun(1,2)
myFun(1,3)
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(training_3)[j]) ) == 1)  {
print(names(myTraining[i]))
}
}
}
}
training_3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(training_3)) {
if( length( grep(names(myTraining[i]), names(training_3)[j]) ) == 1)  {
print(names(myTraining[i]))
}
}
}
}
training_3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(training_3)) {
if( length( grep(names(myTraining[i]), names(training_3)[j]) ) == 1)  {
training_3 <- training_3[ , -j]
}
}
}
}
length(names(training_3))
training_3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
training_3 <- training_3[ , -i]
}
}
length(names(training_3))
training_3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
print(names(myTraining)[i])
}
}
dim(myTraining)
myFun <- function(){
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
print(names(myTraining)[i])
}
}
}
length(myFun)
myFun()
training_3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(training_3)) {
if( length( grep(names(myTraining[i]), names(training_3)[j]) ) == 1)  {
training_3 <- training_3[ , -j]
}
}
}
}
myTraining[2, -58]
dim(testing)
testing
predTest <- predict(fitRF,newdata=testing,type="class")
predTest
library(randomForest)
set.seed(12345)
fitRF <- randomForest(classe ~ ., data=myTraining)
predRF <- predict(fitRF, myTesting, type = "class")
confusionMatrix(predRF, myTesting$classe)
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58])  # remove the classe column
myTesting <- myTesting[clean1]         # allow only variables in myTesting that are also in myTraining
testing <- testing[clean2]             # allow only variables in testing that are also in myTraining
trLoc = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
tstLoc = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trLoc,destfile = "training.csv")
download.file(tstLoc,destfile = "testing.csv")
training <- read.csv("training.csv",na.strings = c("NA","#DIV/0!",""))
testing <- read.csv("testing.csv",na.string=c("NA","#DIV/0!",""))
library(caret)
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]
nzv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv$nzv==FALSE]
myTraining <- myTraining[c(-1)]
training_3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(training_3)) {
if( length( grep(names(myTraining[i]), names(training_3)[j]) ) == 1)  {
training_3 <- training_3[ , -j]
}
}
}
}
myTraining <- training_3
rm(training_3)
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58])  # remove the classe column
myTesting <- myTesting[clean1]         # allow only variables in myTesting that are also in myTraining
testing <- testing[clean2]             # allow only variables in testing that are also in myTraining
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
# To get the same class between testing and myTraining
testing <- rbind(myTraining[2, -58] , testing)
# Remove column 1 from the testing data set
testing <- testing[-1,]
library(randomForest)
set.seed(12345)
fitRF <- randomForest(classe ~ ., data=myTraining)
predRF <- predict(fitRF, myTesting, type = "class")
confusionMatrix(predRF, myTesting$classe)
predTest <- predict(fitRF,newdata=testing,type="class")
predTest
names(testing)
?rbind
?write.csv
predRF
fitRF
cf <- confusionMatrix(predRF, myTesting$classe)
cf
cf$overall
cf$overall[1]
install.packages("shiny")
library(shiny)
runApp('Desktop/Datascience/courses-master/09_DevelopingDataProducts/shiny-testing/HelloShiny')
?mean
?colSums
?show
?methods
?dgamma
?methods
?S4Methods
??S4Methods
?methods
showMethods()
getMethod()
getClass()
getS3method()
?showMethods
?methods
?show
?colSums
install.packages(devtools)
install.packages("devtools")
library(devtools)
install_github("ropensci/plotly")
plot_ly(mtcars, x = hp, y = mpg,
mode = "markers",
color = wt,
text=paste("Weight:", wt))
library(plotly)
plot_ly(mtcars, x = hp, y = mpg,
mode = "markers",
color = wt,
text=paste("Weight:", wt))
data(mtcars)
names(data)
mtcars
plot_ly(mtcars, x = hp, y = mpg, mode = "markers",color = wt,text=paste("Weight:", wt))
plot_ly(mtcars, x = mtcars$hp, y = mtcars$mpg, mode = "markers",color = mtcars$wt,text=paste("Weight:", wt))
plot_ly(mtcars, x = mtcars$hp, y = mtcars$mpg, mode = "markers",color = mtcars$wt,text=paste("Weight:", plot_ly(mtcars, x = mtcars$hp, y = mtcars$mpg, mode = "markers",color = mtcars$wt,text=paste("Weight:", wt))$wt))
plot_ly(mtcars, x = mtcars$hp, y = mtcars$mpg, mode = "markers",color = mtcars$wt,text=paste("Weight:", mtcars$wt))
library(ggplot2)
g = ggplot(mtcars, aes(x=wt,y=mpg))
g = g + geom_point(aes(color=factor(cyl)))
ggplotly(g)
library(ggplot2)
g = ggplot(mtcars, aes(x=wt,y=mpg))
g = g + geom_point(aes(color=factor(cyl)))
ggplotly(g)
p <- plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length)
plot(p)
plot_ly(mtcars, x = hp, y = mpg)
plot_ly(mtcars, x = mtcars$hp, y = mtcars$mpg)
p <- plot_ly(data=mtcars,x=mtcars$wt,y=mtcars$mpg)
plot(p)
library(plotly)
p <- plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length)
p
install.packages("webshot")
summary(mtcars)
names(mtcars)
install.packages("rJava")
setwd("/Users/anarasimhan/Desktop/Datascience/courses-master/09_DevelopingDataProducts/shiny-testing/helloworldanandbn")
imdb <- read.csv("data/movie_metadata.csv")
dim(idmb)
dim(imdb)
imdb <- imdb[complete.cases(imdb),]
dim(imdb)
library(caret)
corMatrix <- cor(imdb)
imdb_1 <- lapply(imdb,levels)
head(imdb_1)
imdb_1 <- lapply(imdb,as.integer)
head(imdb_1,5)
corMatrix <- cor(imdb_1)
class(imdb_1)
str(imdb_1)
imdb_1 <- as.data.frame(imdb_1)
str(imdb_1)
corMatrix <- cor(imdb_1)
corMatrix
plot(corMatrix)
View(corMatrix)
model <- lm(gross~.,data=imdb_1)
summary(model)
plot(model)
imdb_1 <- imdb_1[complete.cases(imdb_1),]
dim(imdb_1)
varImp(imdb_1)
varImp(model)
featurePlot(x=imdb_1[,c("duration","color","budget")],y = imdb_1$gross,plot="pairs")
featurePlot(x=imdb_1[,c("duration","color","budget")],y = imdb_1$gross,plot="density")
?caret
library(caret)
?caret
vImp <- varImp(imdb_1,scale=FALSE)
vImp <- varImp(as.data.frame(imdb_1),scale=FALSE)
vImp <- varImp(model,scale=FALSE)
plot(vImp,top=5)
plot(vImp)
vImp
vImp <- varImp(model,scale=TRUE)
vImp
nzv <- nearZeroVar(imdb_1, saveMetrics= TRUE)
nzv$nzv
names(imdb)[nzv$nzv]
nzv[nzv$nzv,]
imdbCor <- cor(imdb_1)
highCorr <- sum(abs(imdbCor[upper.tri(imdbCor)]) > .999)
highCorr
summary(imdbCor[upper.tri(imdbCorr)])
summary(imdbCor[upper.tri(imdbCor)])
descrCor <- cor(imdb_1)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
highlyCorDescr
filteredDescr <- filteredDescr[,-highlyCorDescr]
filteredDescr <- imdb_1[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr)
summary(descrCor2[upper.tri(descrCor2)])
names(imdb_1)
linCombos <- findLinearCombos(imdb_1)
linCombos
library(ggplot2)
g <- ggplot(imdb,aes(x=language,y=gross))
g + geom_point() + geom_smooth(method="lm")
g <- ggplot(imdb,aes(x=color,y=gross))
g + geom_point() + geom_smooth(method="lm")
g <- ggplot(imdb,aes(x=num_voted_users,y=gross))
g + geom_point() + geom_smooth(method="lm")
g <- ggplot(imdb,aes(x=cast_total_facebook_likes,y=gross))
g + geom_point() + geom_smooth(method="lm")
g <- ggplot(imdb,aes(x=title_year,y=gross))
g + geom_point() + geom_smooth(method="lm")
table (imdb_1$color)
table (imdb_1$director_name)
clear
clear()
head(imdb,2)
g <- ggplot(imdb,aes(x=country,y=gross))
g + geom_point() + geom_smooth(method="lm")
